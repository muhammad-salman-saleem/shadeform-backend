meta {
  name: createInstance
  type: http
  seq: 2
}

post {
  url: http://localhost:3000/instances/create
  body: json
  auth: none
}

body:json {
  {
    "cloud": "massedcompute",
    "region": "us-central-2",
    "shade_instance_type": "A6000",
    "shade_cloud": true,
    "name": "cool-gpu-server",
    "launch_configuration": "{\"type\": \"docker\", \"docker_configuration\": {\"image\": \"vllm/vllm-openai:latest\", \"args\": \"--model mistralai/Mistral-7B-v0.1\", \"shared_memory_in_gb\": 8, \"envs\": [{\"name\": \"HUGGING_FACE_HUB_TOKEN\", \"value\": \"hugging_face_api_token\"}], \"port_mappings\": [{\"host_port\": 80, \"container_port\": 8000}], \"volume_mounts\": [{\"host_path\": \"~/.cache/huggingface\", \"container_path\": \"/root/.cache/huggingface\"}]}}",
    "os": "ubuntu22.04_cuda12.2_shade_os"
  }
}
